predictors
adData
head(AddData)
adData.head()
adData.head
adData
predictors
head(predictors)
diagnosis
testIndex
training
length(training)
len(testing)
length(testing)
length(adData)
length(testIndex)
library(AppliedPredictiveModeling)
library(caret)
data(AlzheimerDisease)
adData = data.frame(diagnosis, predictors)
testIndex = createDataPartition(diagnosis, p=0.50, list=FALSE)
training = adData[-testIndex,]
testing = adData[testIndex,]
testing
length(testing)
length(training)
nrow(training)
nrow(testing)
nrow(adData)
library(AppliedPredictiveModeling)
data(concrete)
library(caret)
set.seed(1000)
inTrain = createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
training = mixtures[ inTrain,]
testing = mixtures[-inTrain,]
inTrain
library(AppliedPredictiveModeling)
library(caret)
data(AlzheimerDisease)
data
adData = data.frame(diagnosis,predictors)
adData
head(adData)
adData = data.frame(diagnosis,predictors)
testIndex = createDataPartition(diagnosis, p = 0.50,list=FALSE)
training = adData[-testIndex,]
testing = adData[testIndex,]
adData = data.frame(diagnosis,predictors)
trainIndex = createDataPartition(diagnosis,p=0.5,list=FALSE)
training = adData[trainIndex,]
testing = adData[-trainIndex,]
length(testing)
length(training)
len(adData)
length(adData)
adData = data.frame(diagnosis,predictors)
testIndex = createDataPartition(diagnosis, p = 0.50,list=FALSE)
training = adData[-testIndex,]
testing = adData[testIndex,]
length(training)
length(training)
training = adData[-testIndex,]
nobs(training)
num(training)
nrows(training)
numrows(training)
nrow(training)
nrow(testing)
nrow(addata)
nrow(aDdata)
nrow(adData)
training = adData[-testIndex,]
testing = adData[testIndex,]
nrow(training)
nrow(testing)
adData = data.frame(diagnosis,predictors)
trainIndex = createDataPartition(diagnosis,p=0.5,list=FALSE)
training = adData[trainIndex,]
testing = adData[-trainIndex,]
nrow(training)
nrow(testing)
#2
library(AppliedPredictiveModeling)
data(concrete)
library(caret)
set.seed(1000)
inTrain = createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
training = mixtures[ inTrain,]
testing = mixtures[-inTrain,]
suppressMessages(library(dplyr))
suppressMessages(library(Hmisc))
suppressMessages(library(gridExtra))
training <- mutate(training, index=1:nrow(training))
cutIndex <- cut2(training$index, g=10)
breaks <- 10
qplot(index, CompressiveStrength, data=training, color=cut2(training$Cement, g=breaks))
install.packages(Hmisc)
install.packages('Hmisc'')
df
df)
df
adf
as]df
x=4
aslkjdfalksdjfl
sdaf
osaotr
q34t
43t
43
>>>
x.
library(AppliedPredictiveModeling)
data(concrete)
library(caret)
set.seed(1000)
inTrain = createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
training = mixtures[ inTrain,]
testing = mixtures[-inTrain,]
install.packages('dplyr')
install.packages('Hmisc')
install.packages("Hmisc")
install.packages('gridExtra')
training <- mutate(training, index=1:nrow(training))
library(dplyr)
library(Hmisc)
library(gridExtra)
training <- mutate(training, index=1:nrow(training))
cutIndex <- cut2(training$index, g=10)
breaks <- 10
qplot(index, CompressiveStrength, data=training, color=cut2(training$Cement, g=breaks))
library(AppliedPredictiveModeling)
data(concrete)
library(caret)
set.seed(1000)
inTrain = createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
training = mixtures[ inTrain,]
testing = mixtures[-inTrain,]
hist(training$Superplasticizer, breaks=20)
hist(log(training$Superplasticizer+1), breaks=20)
#4
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]training = adData[ inTrain,]
testing = adData[-inTrain,]
IL_col_idx <- grep("^[Ii][Ll].*", names(training))
preObj <- preProcess(training[, IL_col_idx], method=c("center", "scale", "pca"), thresh=0.8)
preObj
IL_col_idx <- grep("^[Ii][Ll].*", names(inTrain))
IL_col_idx
inTrain.head()
head(inTrain)
inTrain
training=adData[inTrain,]
#4
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]training = adData[ inTrain,]
testing = adData[-inTrain,]
training=adData[inTrain,]
#4
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]training = adData[ inTrain,]
testing = adData[-inTrain,]
training=adData[inTrain,]
training
IL_col_idx <- grep("^[Ii][Ll].*", names(training))
IL_col_idx
preObj <- preProcess(training[, IL_col_idx], method=c("center", "scale", "pca"), thresh=0.8)
preObj
names(preObj)
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]training = adData[ inTrain,]
testing = adData[-inTrain,]
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]training = adData[ inTrain,]
testing = adData[-inTrain,]
training=adData[inTrain,]
IL_col_idx <- grep("^[Ii][Ll].*", names(training))
suppressMessages(library(dplyr))
new_training <- training[, c(names(training)[IL_col_idx], "diagnosis")]
names(new_training)
IL_col_idx <- grep("^[Ii][Ll].*", names(testing))
suppressMessages(library(dplyr))
new_testing <- testing[, c(names(testing)[IL_col_idx], "diagnosis")]
names(new_testing)
# compute the model with non_pca predictors
non_pca_model <- train(diagnosis ~ ., data=new_training, method="glm")
# apply the non pca model on the testing set and check the accuracy
non_pca_result <- confusionMatrix(new_testing[, 13], predict(non_pca_model, new_testing[, -13]))
non_pca_result
non_pca_model <- train(diagnosis ~ ., data=new_training, method="glm")
install.packages('e1071', dependencies=TRUE)
non_pca_model <- train(diagnosis ~ ., data=new_training, method="glm")
non_pca_result <- confusionMatrix(new_testing[, 13], predict(non_pca_model, new_testing[, -13]))
non_pca_result
# perform PCA extraction on the new training and testing sets
pc_training_obj <- preProcess(new_training[, -13], method=c('center', 'scale', 'pca'), thresh=0.8)
pc_training_preds <- predict(pc_training_obj, new_training[, -13])
pc_testing_preds <- predict(pc_training_obj, new_testing[, -13])
# compute the model with pca predictors
pca_model <- train(new_training$diagnosis ~ ., data=pc_training_preds, method="glm")
# apply the PCA model on the testing set
pca_result <- confusionMatrix(new_testing[, 13], predict(pca_model, pc_testing_preds))
pca_result
pca_result
non_pca_result
#4
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]training = adData[ inTrain,]
testing = adData[-inTrain,]
training=adData[inTrain,]
IL_col_idx <- grep("^[Ii][Ll].*", names(training))
preObj <- preProcess(training[, IL_col_idx], method=c("center", "scale", "pca"), thresh=0.9)
names(preObj)
pre_Obj
preObj <- preProcess(training[, IL_col_idx], method=c("center", "scale", "pca"), thresh=0.9)
preObj
library(AppliedPredictiveModeling)
data(segmentationOriginal)
library(caret)
set.seed(125)
inTrain <- data$Case == "Train"
trainData <- data[inTrain, ]
testData <- data[!inTrain, ]
cartModel <- train(Class ~ ., data=trainData, method="rpart")
set.seed(125)
inTrain <- data$Case == "Train"
data <- segmentationOriginal
inTrain <- data$Case == "Train"
trainData <- data[inTrain, ]
testData <- data[!inTrain, ]
cartModel <- train(Class ~ ., data=trainData, method="rpart")
cartModel
data.head()
head(data)
cartModel$finalModel
suppressMessages(library(rattle))
library(rpart.plot)
fancyRpartPlot(modFit$finalModel)
suppressMessages(library(rattle))
install.packages('rattle')
suppressMessages(library(rattle))
library(rpart.plot)
fancyRpartPlot(modFit$finalModel)
library(rpart.plot)
fancyRpartPlot(modFit$finalModel)
suppressMessages(library(rattle))
library(rpart.plot)
fancyRpartPlot(cartModel$finalModel)
suppressMessages(library(rattle))
library(rpart.plot)
library(AppliedPredictiveModeling)
data(segmentationOriginal)
library(caret)
#1
set.seed(125)
data <- segmentationOriginal
inTrain <- data$Case == "Train"
trainData <- data[inTrain, ]
testData <- data[!inTrain, ]
cartModel <- train(Class ~ ., data=trainData, method="rpart")
cartModel$finalModel
suppressMessages(library(rattle))
library(rpart.plot)
fancyRpartPlot(cartModel$finalModel)
plot(cartModel$finalModel, uniform=T)
source('~/.active-rstudio-document', echo=TRUE)
plot(cartModel$finalModel, uniform=T)
text(cartModel$finalModel, cex=0.8)
library(pgmm)
data(olive)
olive = olive[,-1]
install.packages(pgmm)
install.packages('pgmm')
library(pgmm)
data(olive)
olive = olive[,-1]
olive
head(olive)
newdata = as.data.frame(t(colMeans(olive)))
modolive <- train(Area ~ ., method = "rpart", data = olive)
predict(modolive, newdata = newdata)
library(ElemStatLearn)
data(SAheart)
set.seed(8484)
train = sample(1:dim(SAheart)[1], size = dim(SAheart)[1] / 2, replace = F)
trainSA = SAheart[train, ]
testSA = SAheart[-train, ]
install.packages('ElemStatLearn')
library(ElemStatLearn)
data(SAheart)
set.seed(8484)
train = sample(1:dim(SAheart)[1], size = dim(SAheart)[1] / 2, replace = F)
trainSA = SAheart[train, ]
testSA = SAheart[-train, ]
missClass = function(values, prediction){sum(((prediction > 0.5) * 1) != values) / length(values)}
set.seed(13234)
modelSA <- train(chd ~ age + alcohol + obesity + tobacco + typea + ldl,
data = trainSA, method = "glm", family = "binomial")
missClass(testSA$chd, predict(modelSA, newdata = testSA))
missClass(trainSA$chd, predict(modelSA, newdata = trainSA))
library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
vowel.train$y <- as.factor(vowel.train$y)
vowel.test$y <- as.factor(vowel.test$y)
set.seed(33833)
library(randomForest)
modvowel <- randomForest(y ~ ., data = vowel.train)
order(varImp(modvowel), decreasing = T)
#1
library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
vowel.train$y <- as.factor(vowel.train$y)
vowel.test$y <- as.factor(vowel.test$y)
set.seed(33833)
mod_rf <- train(y ~ ., data = vowel.train, method = "rf")
mod_gbm <- train(y ~ ., data = vowel.train, method = "gbm")
pred_rf <- predict(mod_rf, vowel.test)
pred_gbm <- predict(mod_gbm, vowel.test)
vowel.train$y <- as.factor(vowel.train$y)
vowel.test$y <- as.factor(vowel.test$y)
set.seed(33833)
library(caret)
mod_rf <- train(y ~ ., data = vowel.train, method = "rf")
mod_gbm <- train(y ~ ., data = vowel.train, method = "gbm")
mod_rf <- train(y ~ ., data = vowel.train, method = "rf")
mod_rf
mod_gbm <- train(y ~ ., data = vowel.train, method = "gbm")
pred_rf <- predict(mod_rf, vowel.test)
pred_gbm <- predict(mod_gbm, vowel.test)
confusionMatrix(pred_rf, vowel.test$y)$overall[1]
confusionMatrix(pred_rf, vowel.test$y)$overall
confusionMatrix(pred_rf, vowel.test$y)$overall[1]
confusionMatrix(pred_gbm, vowel.test$y)$overall[1]
predDF <- data.frame(pred_rf, pred_gbm, y = vowel.test$y)
# Accuracy among the test set samples where the two methods agree
sum(pred_rf[predDF$pred_rf == predDF$pred_gbm] ==
predDF$y[predDF$pred_rf == predDF$pred_gbm]) /
sum(predDF$pred_rf == predDF$pred_gbm)
confusionMatrix(pred_rf, vowel.test$y)$overall[1]
confusionMatrix(pred_gbm, vowel.test$y)$overall[1]
#1
library(ElemStatLearn)
library(caret)
data(vowel.train)
data(vowel.test)
vowel.train$y <- as.factor(vowel.train$y)
vowel.test$y <- as.factor(vowel.test$y)
set.seed(33833)
mod_rf <- train(y ~ ., data = vowel.train, method = "rf")
mod_gbm <- train(y ~ ., data = vowel.train, method = "gbm")
pred_rf <- predict(mod_rf, vowel.test)
pred_gbm <- predict(mod_gbm, vowel.test)
confusionMatrix(pred_rf, vowel.test$y)$overall[1]
confusionMatrix(pred_gbm, vowel.test$y)$overall[1]
predDF <- data.frame(pred_rf, pred_gbm, y = vowel.test$y)
sum(pred_rf[predDF$pred_rf == predDF$pred_gbm] ==
predDF$y[predDF$pred_rf == predDF$pred_gbm]) /
sum(predDF$pred_rf == predDF$pred_gbm)
library(caret)
library(gbm)
set.seed(3433)
library(AppliedPredictiveModeling)
data(AlzheimerDisease)
adData = data.frame(diagnosis, predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[inTrain, ]
testing = adData[-inTrain, ]
set.seed(62433)
mod_rf <- train(diagnosis ~ ., data = training, method = "rf")
mod_gbm <- train(diagnosis ~ ., data = training, method = "gbm")
mod_lda <- train(diagnosis ~ ., data = training, method = "lda")
pred_rf <- predict(mod_rf, testing)
pred_gbm <- predict(mod_gbm, testing)
pred_lda <- predict(mod_lda, testing)
predDF <- data.frame(pred_rf, pred_gbm, pred_lda, diagnosis = testing$diagnosis)
combModFit <- train(diagnosis ~ ., method = "rf", data = predDF)
combPred <- predict(combModFit, predDF)
confusionMatrix(pred_rf, testing$diagnosis)$overall[1]
confusionMatrix(pred_gbm, testing$diagnosis)$overall[1]
confusionMatrix(pred_lda, testing$diagnosis)$overall[1]
confusionMatrix(combPred, testing$diagnosis)$overall[1]
install.packages('elasticnet')
library(elasticnet)
set.seed(233)
mod_lasso <- train(CompressiveStrength ~ ., data = training, method = "lasso")
set.seed(3523)
library(AppliedPredictiveModeling)
library(elasticnet)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[inTrain, ]
testing = concrete[-inTrain, ]
set.seed(3523)
library(AppliedPredictiveModeling)
library(elasticnet)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[inTrain, ]
testing = concrete[-inTrain, ]
set.seed(233)
mod_lasso <- train(CompressiveStrength ~ ., data = training, method = "lasso")
mod_lasso
plot.enet(mod_lasso$finalModel, xvar = "penalty", use.color = TRUE)
library(lubridate)  # For year() function below
dat = read.csv("P:/Documents/DataScience/MachineLearning/gaData.csv")
install.packages('')
install.packages('lubridate')
library(lubridate)  # For year() function below
dat = read.csv("P:/Documents/DataScience/MachineLearning/gaData.csv")
data
training = dat[year(dat$date) < 2012, ]
testing = dat[(year(dat$date)) > 2011, ]
tstrain = ts(training$visitsTumblr)
library(forecast)
install.packages('forecast')
mod_ts <- bats(tstrain)
fcast <- forecast(mod_ts, level = 95, h = dim(testing)[1])
sum(fcast$lower < testing$visitsTumblr & testing$visitsTumblr < fcast$upper) /
dim(testing)[1]
fcast <- forecast(mod_ts, level = 95, h = dim(testing)[1])
library(forecast)
mod_ts <- bats(tstrain)
fcast <- forecast(mod_ts, level = 95, h = dim(testing)[1])
sum(fcast$lower < testing$visitsTumblr & testing$visitsTumblr < fcast$upper) /
dim(testing)[1]
set.seed(3523)
library(AppliedPredictiveModeling)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[inTrain, ]
testing = concrete[-inTrain, ]
library(e1071)
set.seed(325)
library(e1071)
mod_svm <- svm(CompressiveStrength ~ ., data = training)
pred_svm <- predict(mod_svm, testing)
accuracy(pred_svm, testing$CompressiveStrength)
install.packages('manipulate')
library(cars)
cars
library(manipulate)
myPlot <- function(s) {
plot(cars$dist - mean(cars$dist), cars$speed - mean(cars$speed))
abline(0, s)
}
manipulate(myPlot(s), s = slider(0, 2, step = 0.1))
manipulate(myPlot, s = slider(0, 2, step = 0.1))
manipulate(myPlot(s), s = slider(0, 2, step = 0.1))
manipulate(myPlot(s), slider = x(0, 2, step = 0.1))
manipulate(myPlot(s), x.s = slider(0, 2, step = 0.1))
manipulate(myPlot(s), s = slider(0, 2, step = 0.1))
install.packages('rCharts')
data(airquality)
airquality
dTable(airquality, sPaginationType = "full_numbers")
d <- data.frame(airquality, stringsAsFactors = FALSE)print(d)
library(rCharts)
library(rChart)
library(rCharts)
install.packages('rCharts')
ftype(show)
library pryr
library(pryr)
install.packages('pryr')
libaray(pryr)
library(pryr)
ftype(mean)
ftype(predict)
ftype(show)
ftype(dgamma)
ftype(lm)
ftype(show)
ftype(mean)
ftype(predict)
ftype(ColSums)
ftype(colSums)
install.packages('shiny')
library(shiny)
runapp('P:/Documents/DataScience/DataProducts/CourseProject')
library(shiny)
runApp('P:/Documents/DataScience/DataProducts/CourseProject')
runapp()
\
runApp('P:/Documents/DataScience/DataProducts/CourseProject')
